\section{Conclusion}
\label{sec:conclusion}
We have seen that using multiple processes
for data-parallel processing within our machine learning model allows a significant improvement in run-time.
Unfortunately, this does not improve the classification performance.
The 4 different classifies Logistic Regression,
SVM, AdaBoost and KNN
all have the benefits and disadvantages.
We would suggest that users should use the model that more accurately detects
the emotion that they are interested in if there were to use our code.
Our use of ensemble methods was not the best performing so again we should
ask ourselves if our previous models were over-fitting and if using a voting
classifier provides us with a better overall result. 
There are still several opportunities in this project that can be tackled, 
such as using evolutionary algorithms (such as GA) to tune the model coefficients. 
Also, the regularization method can be used to tune specific weights. 
Furthermore, Decision Trees and Random Forest algorithms can be utilized to 
improve our ensemble model further.